
# Données manquantes { }

```{r, out.width=c("50%"), echo=F}
knitr::include_graphics(here::here("images", "missingness.png"))
knitr::include_graphics(here::here("images", "missingness_overview.png"))
```

Dans ce chapitre nous allons :  
1) Évaluer l'ampleur des données manquantes  
2) Filtrer les lignes en fonction des données manquantes  
3) Faire des graphiques des données manquantes au cours du temps  
4) Gérer comment les `NA` apparaissent dans les graphes  
5) Imputer des données manquantes : MCAR, MAR, MNAR  



<!-- ======================================================= -->
## Étapes préliminaires { }

### Importation des paquets {.unnumbered}  

Ces lignes de code chargent les paquets nécessaires aux analyses. Dans ce guide, nous mettons l'accent sur `p_load()` de **pacman**, qui installe le paquet si nécessaire *puis* l'importe pour l'utiliser. Vous pouvez également charger les paquets installés avec `library()` de **base** R. Voir la page sur [bases de R](#rbasics) pour plus d'informations sur les paquets R.  

```{r}
pacman::p_load(
  rio,           # import des fichiers
  tidyverse,     # gestion des données + graphiques (ggplot2)
  naniar,        # bilan des données manquantes
  mice           # imputation
)
```


### Importation des données {.unnumbered}

Nous importons un jeu de données de cas d'une épidémie d'ébola fictive. WPour reproduire les étapes, <a href='https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'>cliquez pour télécharger la linelist "propre"</a> (as .rds file). Importez vos données avec la fonction `import()` du paquet **rio** (elle accepte de nombreux types de fichiers comme .xlsx, .rds, .csv - voir la page [Importation et exportation des données](import_export) pour plus de détails).  

```{r, echo=F}
# importer la linelist dans R
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r, eval=F}
# importer la linelist dans R
linelist <- import("linelist_cleaned.rds")
```

Les cinquantes premières lignes sont affichées ci-dessous :  

```{r, message=FALSE, echo=F}
# display the linelist data as a table
DT::datatable(head(linelist, 50), rownames = FALSE, filter = "top",
              options = list(pageLength = 5, scrollX = T), 
              class = 'white-space: nowrap' )
```


### Conversion des données manquantes lors de l'import {.unnumbered}  

Il faut être particulièrement attentif aux valeurs qui doivent être classifiées comme "manquantes" lors de l'import des données. Des données manquantes peuvent par exemple être indiquées par 99, 999, "Manquant", un espace vide (" ") ou des cellules vides (""). Vous pouvez les convertir en `NA` (la ma,ière dont R code les données manquantes, pour _"Non available"_) via la fonction d'importation des données.  
Pour plus de détails, consultez la page sur l'importation des [Données manquantes](#import_missing), car la syntaxe exacte varie selon le type de fichier.  


<!-- ======================================================= -->
## Valeurs manquantes dans R { }

Nous explorons ci-dessous les façons dont les données manquantes sont représentées et évaluées dans R.  

### `NA` {.unnumbered}  

En R, les valeurs manquantes sont représentées par un mot réservé (spécial) : `NA`. Notez que ce mot est tapée *sans* guillemets, et ne doit pas être confondue avec une chaîne de caractères "NA" (également une parole des Beatles de la chanson _Hey Jude_).  

Les données butes peuvent avoir utilisés d'autre codes pour représenter les données manquantes, comme "99", "Manquant", "Inconnu", une valeur de caractère vide "" qui ressemble à un "blanc", ou un espace simple " ". Tenez-en compte et réfléchissez à l'opportunité de [les convertir en `NA` pendant l'importation](#import_missing) ou pendant le nettoyage des données avec `na_if()`.  


A l'inverse, lors du nettoyage des données, il peut également être pertinent de convertir des `NA` en "Manquante" (ou autre) avec les fonctions `replace_na()` ou `fct_explicit_na()` dans le cas des facteurs.    


### `NA` et ses dérivés {.unnumbered}  

La plupart du temps, `NA` représente une valeur manquante et il n'y a pas besoin de se poser plus de questions que ça. Cependant, dans certaines circonstances, il peut y avaoit besoin de *variations* de `NA` spécifiques à une classe d'objet (caractère, numérique, etc.). C'est rare, mais il faut en être conscient.  

Parmis ces cas rares, la création d'une nouvelle colonne avec la fonction **dplyr** `case_when()` est le plus commun. Comme décrit dans la page [Nettoyage des données et fonctions de base](#clean_case_when), cette fonction évalue chaque ligne du dataframe, détermine si les lignes répondent à des critères logiques spécifiés (partie droite du code), et attribue la nouvelle valeur correcte (partie gauche du code). *Important : toutes les valeurs du côté droit doivent être de la même classe*.  

```{r, eval=F}
linelist <- linelist %>% 
  
  # Créer une nouvelle colonne "age_years" à partir de la colonne "age"
  mutate(age_years = case_when(
    age_unit == "years"  ~ age,    # si l'unité est années => garder la valeur originale
    age_unit == "months" ~ age/12, # l'unité est en mois, diviser par 12
    is.na(age_unit)      ~ age,    # si l'unité est manquante, supposer que l'age est en années
    TRUE                 ~ NA_real_)) # sinon, définir age comme valeur manquante
```

Afin que toutes les valeurs spécifiées du côté droit des équations aient le même type, il faut utiliser des dérivés de `NA` avec un type connu (voir ci dessous). Si les autres valeurs de droite sont des chaines de caractères, on peut utiliser `NA_character_` ou envisager d'utiliser "Manquant" à la place. Si les valeurs sont toutes numériques, utiliser `NA_real_`. S'il s'agit de dates ou de valeurs logiques, on peut conserver `NA`.  

* `NA` - à utiliser pour les dates ou les booléens VRAI/FAUX  
* `NA_character_` - à utiliser pour les chaines de caractères   
* `NA_real_` - pour les valeurs numériques  



Encore une fois, il est peu probable que vous rencontriez ces variations, hors utilisation de `case_when()` pour créer une nouvelle colonne. Consultez la [documentation R sur NA](https://stat.ethz.ch/R-manual/R-devel/library/base/html/NA.html) pour plus d'informations. 



### `NULL` {.unnumbered}  

`NULL` est un autre mot réservée en R. C'est la représentation logique d'une déclaration qui n'est ni vraie ni fausse. Elle est retournée par des expressions ou des fonctions dont les valeurs sont indéfinies. En général, n'assignez pas NULL comme valeur, à moins d'écrire des fonctions ou peut-être une [**shiny** app](#shiny) pour retourner `NULL` dans des scénarios spécifiques.  

La nullité peut être évaluée avec `is.null()` et la conversion peut être faite avec `as.null()`.  

Voir cet [article de blog](https://www.r-bloggers.com/2010/04/r-na-vs-null/) sur la différence entre `NULL` et `NA`. 



### `NaN` {.unnumbered}  

Les valeurs impossibles sont représentées par le mot spécial `NaN`. Par exemple, R renvoi `NaN` si vous lui demandez de diviser 0 par 0. `NaN` peut être évalué avec `is.nan()`. Il existe également des fonctions complémentaires comme `is.infinite()` et `is.finite()`. 


### `Inf` {.unnumbered}  

`Inf` représente une valeur infinie, telle que l'on peut parexemple obtenir en divisant un nombre par zéro.  

Pour comprendre comment ce type de valeurs peuvent affecter vos analyses, imaginons que vous avez un vecteur `z` qui contient ces valeurs : `z <- c(1, 22, NA, Inf, NaN, 5)`.  

Si vous voulez utiliser la fonction `max()` sur la colonne pour trouver la valeur la plus élevée, vous pouvez utiliser le `na.rm = TRUE` pour omettre le `NA` du calcul. Mais celà n’enlèvera pas les `Inf` et `NaN`, ce qui fait que le résultat retourné sera `Inf`. Pour résoudre ce problème, vous pouvez utiliser les crochets `[ ]` et `is.finite()` pour effectuer un sous-ensemble de sorte que seules les valeurs finies soient utilisées pour le calcul : `max(z[is.finite(z)])`.  


```{r, eval=F}
z <- c(1, 22, NA, Inf, NaN, 5)
max(z)                           # retourne NA
max(z, na.rm=T)                  # retourne Inf
max(z[is.finite(z)])             # retourne 22
```


### Exemples {.unnumbered}  


Instruction R | Sortie
----------|--------------
`5 / 0` | `Inf`  
`0 / 0` | `NaN`  
`5 / NA` | `NA`  
`5 / Inf | `0`  
`NA - 5` | `NA`  
`Inf / 5` | `Inf`  
`class(NA)` | "logical"  
`class(NaN)` | "numeric"  
`class(Inf)` | "numeric"  
`class(NULL)` | "NULL"  

Un message d'avertissement que vous rencontrerez certainement est "NAs introduits par coercition". Cela peut se produire si vous tentez d'effectuer une conversion illégale, par exemple en insérant une chaîne caractère dans un vecteur qui contient des valeurs numérique.   

```{r}
as.numeric(c("10", "20", "thirty", "40"))
```

Note : `NULL` est ignoré dans un vecteur.  

```{r}
my_vector <- c(25, NA, 10, NULL)  # définit
my_vector                         # affiche
```


Note : tenter de calculer la variance sur une valeur unique retourne également un `NA`.  

```{r}
var(22)
```


<!-- ======================================================= -->
## Fonctions utiles { }

Voici quelques fonctions utiles en **base** R pour détecter et gérer les valeurs manquantes.


### `is.na()` et `!is.na()` {.unnumbered}  

`is.na()` permet d'identifier les valeurs manquantes. Pour identifier les valeurs non manquantes il suffit d'utiliser son opposé en ajoutant `!` devant. Ces deux méthodes retournent une valeur logique (`TRUE` ou `FALSE`). Pour rappel, il est possible de sommer le vecteur résultant avec `sum()` pour compter le nombre de `TRUE`. Par exemple :  `sum(is.na(linelist$date_outcome))`.    


```{r}
my_vector <- c(1, 4, 56, NA, 5, NA, 22)
is.na(my_vector)
!is.na(my_vector)
sum(is.na(my_vector))
```


### `na.omit()` {.unnumbered}  

Appliquée à un dataframe, cette fonction de **base** R supprimera les lignes dont  *toutes* les valeurs sont manquantes. Appliquée à un vecteur, elle supprimera les valeurs `NA` de ce vecteur. Par exemple :   


```{r}
na.omit(my_vector)
```

### `drop_na()` {.unnumbered}  

Il s'agit d'une fonction de **tidyr** utile pour [nettoyer des données dans un pipeline](#cleaning_pipeline). Si elle est exécutée sans argument, elle supprime également les lignes dont *toutes* les valeurs sont manquantes. Mais si des noms de colonnes sont spécifiés comme arguments, seules les lignes avec des valeurs manquantes dans ces colonnes seront supprimées.   

Note : on peut utiliser la syntaxe "tidyselect" pour spécifier les colonnes.  


```{r, eval=F}
linelist %>% 
  drop_na(case_id, date_onset, age) # omet les lignes contenant des valeurs manquantes dans une de ces colonnes au moins
```


### `na.rm = TRUE` {.unnumbered}  

Lorsque vous exécutez une fonction mathématique telle que `max()`, `min()`, `sum()` ou `mean()`, la valeur retournée sera `NA` si des valeurs `NA` sont présentes dans les données. Ce comportement par défaut est intentionnel, afin que vous soyez alerté si l'une de vos données est manquante.  

Vous pouvez éviter cela en supprimant les valeurs manquantes du calcul. Pour ce faire, incluez l'argument `na.rm = TRUE` (le "rm" étant une abréviation de "remove").  


```{r}
my_vector <- c(1, 4, 56, NA, 5, NA, 22)

mean(my_vector)     

mean(my_vector, na.rm = TRUE)
```



<!-- ======================================================= -->
## Identifier les valeurs manquantes dans un dataframe { }

Le package **naniar** permet de détecter et de visualiser l'ampleur de la complétude des données (et donc de leur non-complétude) dans un tableau de données.  

```{r}
# installer et charger le paquet
pacman::p_load(naniar)
```

### Quantifier les données manquantes {.unnumbered}

La fonction `pct_miss()` permet de calculer le pourcentage de toutes les valeurs manquantes. La fonction `n_miss()` renvoi le nombre de valeurs manquantes.  


```{r}
# pourcentage de données manquantes sur TOUTES les valeurs du dataframe
pct_miss(linelist)
```

Les deux fonctions ci-dessous renvoient le pourcentage de lignes dont une valeur est manquante ou qui sont entièrement complètes.  

Note : `NA` signifie manquant, mais que ``""` ou `""` ne sont pas considérées comme des valeurs manquantes.  


```{r}
# Pourcentage des lignes avec au moins une valeur manquante
pct_miss_case(linelist)   # utiliser n_miss() pour le nombre de lignes
```

```{r}
# Pourcentage des lignes sans valeur manquante
pct_complete_case(linelist) # utiliser n_complete() pour le nombre
```


### Visualiser les données manquantes {.unnumbered}  

La fonction `gg_miss_var()` renvoi le nombre (ou %) de valeurs manquantes dans chaque colonne. Quelques notes :  

* Vous pouvez ajouter un nom de colonne (pas entre guillemets) à l'argument `facet = ` pour voir le graphique par groupes.  

* Les nombres sont affichés par défault. Pour voir les pourcentages, utilisez `show_pct = TRUE`.  

* Vous pouvez ajouter des étiquettes d'axe et de titre comme pour un `ggplot()` normal avec `+ labs(...)`.  


```{r}
gg_miss_var(linelist, show_pct = TRUE)
```

Ici, les données sont passée à la fonction à l'aide d'un pipe `%>%`. L'argument `facet = ` est utilisé pour séparer les données par outcome.   

```{r}
linelist %>% 
  gg_miss_var(show_pct = TRUE, facet = outcome)
```


La fonction `vis_miss()` permet de visualiser le dataframe sous forme de carte thermique qui indique quelle valeur est manquante. Vous pouvez également `select()` certaines colonnes du cadre de données et ne fournir que ces colonnes à la fonction.  

```{r}
# Carte thermique de la complétude des données à l'échelle du dataframe
vis_miss(linelist)
```


### Explorer et visualiser les relations entre données manquantes{.unnumbered} 

Comment visualiser quelque chose qui n'existe pas ??? Par défaut, `ggplot()` n'affiche pas les points avec des valeurs manquantes dans les graphiques.  

Le package **naniar** propose une solution via la fonction `geom_miss_point()`. Lors de la création d'un nuage de points à partir de deux variables, les paires de valeurs dont l'une est manquante sont montrés en fixant les valeurs manquante à 10% plus bas que la valeur minimale de la colonne, et en les colorant differement.  

Dans le nuage de points ci-dessous, les points rouges sont des enregistrements où la valeur d'une des deux colonne est présente mais où l'autre est manquante. Cela permet de visualiser la distribution des valeurs manquantes par rapport à celle des valeurs non manquantes. 


```{r}
ggplot(
  data = linelist,
  mapping = aes(x = age_years, y = temp)) +     
  geom_miss_point()
```

Pour évaluer les données manquantes dans un dataframe en *stratifiant par une autre colonne*, on peut utiliser la fonction `gg_miss_fct()`, qui retourne une carte thermique du pourcentage de valeurs manquantes dans le dataframe *pour chaque catégorie d'une autre variable* :  


```{r}
gg_miss_fct(linelist, age_cat5)
```

Cette fonction peut aussi être utilisée sur une colonne contenant des dates pour voir comment la complétude des données change au cours du temps :  

```{r}
gg_miss_fct(linelist, date_onset)
```




### Colonnes "fantômes" {.unnumbered}

**naniar** donne la possibilité de créer un jeu de données "fantôme" ("shadow matrix" en Anglais) pour aller plus loin dans l'étude de la distribution des données manquantes. Essentiellement, pour chaque colonne existante la fonction `bind_shadow()` crée une nouvelle colonne binaire contenant soit  `NA`, soit `!NA` (pour "non `NA`"), et lie toutes ces nouvelles colonnes au jeu de données original avec l'appendice "_NA". Cela double le nombre de colonnes - voir ci-dessous :  

```{r}
shadowed_linelist <- linelist %>% 
  bind_shadow()

names(shadowed_linelist)
```

Ces colonnes "fantômes" peuvent être utilisées pour visualiser la proportion de valeurs manquantes dans une colonne en fonction d'une autre colonne.  

Par exemple, le graphique ci-dessous montre la proportion de données manquantes dans la colonne `days_onset_hosp` (le nombre de jours entre l'apparition des symptômes et l'hospitalisation), en fonction de la `date_hospitalisation`. Ici on trace la densité de données manquantes et non manquantes (`color = `) en fonction de la date d'hospitalisation.  

Ce type de visualisation fonctionne mieux si la variable tracée en sur l'axe des abcisses est numérique ou temporelle.   


```{r, message = F}
ggplot(data = shadowed_linelist,   # dataframe augmenté avec les colonnes fantômes
  mapping = aes(x = date_hospitalisation, # colonne numérique ou date
                colour = age_years_NA)) + # colonne fantôme d'intérêt
  geom_density()                          # trace les courbes de densité
```

Les colonnes fantômes peuvent aussi être utilisé comme stratification dans des statistiques descriptives :  

```{r}
linelist %>%
  bind_shadow() %>%                # creation des colonnes fantôme
  group_by(date_outcome_NA) %>%    # groupe par la colonne fantôme de date_outcome
  summarise(across(
    .cols = age_years,             # variable d'intérêt à résumer
    .fns = list("mean" = mean,     # statistiques
                "sd" = sd,
                "var" = var,
                "min" = min,
                "max" = max),  
    na.rm = TRUE))                 # autres arguments des fonctions statistiques
```

**naniar** n'est pas la seule méthode pour représenter la proportion de valeurs manquantes dans une colonne en fonction du temps :   

1) Agréger les données dans une unité de temps pertinente (jours, semaines, etc.), en résumant la proportion d'observations avec `NA` (et toute autre valeur d'intérêt). 

2) Tracez la proportion de données manquantes comme une ligne en utilisant `ggplot()`.  

Dans l'exemple ci-dessous, nous ajoutons une nouvelle colonne pour la semaine à la linelist, regroupons les données par semaine, puis calculons le pourcentage des enregistrements de cette semaine où la valeur est manquante. (note : si vous voulez le % de 7 jours, le calcul sera légèrement différent).  


```{r}
outcome_missing <- linelist %>%
  mutate(week = lubridate::floor_date(date_onset, "week")) %>%   # crée colonne semaine
  group_by(week) %>%      # groupe les lignes par semaine
  summarise(              # pour chaque semaine, résumme : 
    n_obs = n(),          # nombre total d'observations
    outcome_missing = sum(is.na(outcome) | outcome == ""),  # nombre d'obs avec valeur manquante
    outcome_p_miss  = outcome_missing / n_obs,    # proportion d'obs avec valeur manquante
  
    outcome_dead    = sum(outcome == "Death", na.rm=T),     # nb de morts
    outcome_p_dead  = outcome_dead / n_obs) %>%             # prop morts
  
  tidyr::pivot_longer(-week, names_to = "statistic") %>%    # pivote toutes les colonnes sauf la semaine en format long
  filter(stringr::str_detect(statistic, "_p_"))   # garde uniquement les proportions
```

Ensuite, nous traçons la proportion de données manquantes par semaine, sous forme de ligne.  
Référez vous à la page [bases de ggplot](#ggplot_basics) si vous n'êtes pas familier avec le package **ggplot2**.  

```{r, message=F, warning=F}
ggplot(data = outcome_missing) +
    geom_line(
      mapping = aes(x = week, 
                    y = value, 
                    group = statistic, 
                    color = statistic),
      size = 2,
      stat = "identity") +
    labs(title = "Weekly outcomes",
         x = "Week",
         y = "Proportion of weekly records") + 
     scale_color_discrete(
       name = "",
       labels = c("Died", "Missing outcome")) +
    scale_y_continuous(breaks = c(seq(0, 1, 0.1))) +
  theme_minimal() +
  theme(legend.position = "bottom")
```





<!-- ======================================================= -->
## Utiliser des données avec des valeurs manquantes  


### Filtrer les lignes avec valeurs manquantes {.unnumbered}

La fonction `drop_na()` de **dplyr** permet de se débarrasser rapidement des lignes avec des valeurs manquantes.  

La `linelist` originale contient ` nrow(linelist)` lignes. La linelist sans lignes avec des valeurs manquantes contient moins de lignes :   

```{r}
linelist %>% 
  drop_na() %>%     # filtre les lignes sans aucune valeur manquante
  nrow()
```

On peut choisir de ne se débarrasser des lignes avec des valeurs manquantes que dans certaines colonnes :  

```{r}
linelist %>% 
  drop_na(date_onset) %>% # omet les lignes avec des valeurs manquantes dans date_onset
  nrow()
```

On peut passer plusieurs colonnes l'une après l'autre à la fonction, ou utiliser des [fonctions utilitaires de "tidyselect"](#clean_tidyselect):  

```{r}
linelist %>% 
  drop_na(contains("date")) %>% # omet lignes avec NA dans n'importe quelle colonne dont le nom contient "date"
  nrow()
```



<!-- ======================================================= -->
### Gérer les `NA` dans `ggplot()` {.unnumbered}

Il est souvent judicieux de signaler le nombre de valeurs exclues d'un graphique au lecteur du graphique. 

Dans `ggplot()`, la fonction `labs()`a un argument `caption = ` qui ajoute un texte de légende sous le graphique. Vous pouvez utiliser `str_glue()` du package **stringr** pour concaténer valeurs et chaines de caractères ensemble dans une phrase qui s'ajuste automatiquement aux données (voir exemple ci-dessous).    


```{r, eval=F}
labs(
  title = "",
  y = "",
  x = "",
  caption  = stringr::str_glue(
  "n = {nrow(central_data)} from Central Hospital;
  {nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown."))  
```


Notes :   
* l'utilisation de `\n` pour aller à la ligne.   
* si plusieurs colonnes contribuent à ce que des valeurs ne soient pas affichées (par exemple, l'âge ou le sexe si ceux-ci sont reflétés dans le graphique), u=il faut également filtrer sur ces colonnes pour calculer correctement le nombre de valeurs non affichées. 
* on peut sauvegarder la chaîne de caractères en tant qu'objet dans des commandes antérieures à la commande `ggplot()`, et simplement la référencer dans la `str_glue()`.  


<!-- ======================================================= -->
### `NA` dans les facteurs {.unnumbered}

Si votre colonne d'intérêt est un facteur, utilisez `fct_explicit_na()` du package **forcats** pour convertir les valeurs `NA` en une chaine de caractères (plus de détails dans la page [Facteurs](#factors). Par défaut, la nouvelle valeur est "(Missing)" mais cela peut être ajusté via l'argument `na_level =`.   

```{r}
pacman::p_load(forcats)   # charge le package

linelist <- linelist %>% 
  mutate(gender = fct_explicit_na(gender, na_level = "Missing"))

levels(linelist$gender)
```



<!-- ======================================================= -->
## Imputation { }


Lors de certaines analyses de données, il est nécessaire de "combler les lacunes" et d'imputer les données manquantes. En effet, s'il est souvent possible d'analyser un jeu de données après en avoir supprimé toutes les valeurs manquantes, cela peut néanmoins poser des problèmes à plusieurs égards. Voici deux exemples :  

1) Supprimer toutes les observations avec des valeurs manquantes, ou les variables avec une beaucoup de données manquantes peut réduire considérablement la puissance et la capacité à effectuer certains types d'analyse. Par exemple, nous avons vu que seule une faible fraction des lignes de notre linelist ne comporte *aucune* donnée manquante. Si nous supprimions toutes les lignes contenant au moins une donnée manquante, nous perdrions beaucoup d'informations ! De plus, la plupart de nos variables comportent une certaine quantité de données manquantes - pour la plupart des analyses, il n'est probablement pas raisonnable d'éliminer toutes les variables qui comportent beaucoup de données manquantes.

2) Selon la raison pour laquelle vos données sont manquantes, l'analyse des données non manquantes seules peut conduire à des biais et des résultats trompeurs. Par exemple, nous avons vu que de nombreux patients ont des données manquantes dans les colonnes concernant des symptômes importants, comme la fièvre ou la toux. Il est possible que cette information n'ait pas été enregistrée pour les personnes qui ne paraissaient pas sévèrement malades. Dans ce cas, si nous supprimions simplement ces observations, nous exclurions une partie des patients en meilleure santé de notre analyse, ce qui pourrait vraiment biaiser les résultats.

In ne suffit pas seulement d'estimer la quantité des données manquantes, il est également capital de réfléchir à la *raison pour laquelle vos données peuvent être manquantes*. Cela va guider vos choix quant à l'importance de l'imputation des données manquantes, ainsi que de la méthode d'imputation la plus appropriée à votre situation.


### Types de données manquantes {.unnumbered}

Voici les trois grands types de données manquantes, qui correspondent à des mécanismes différents de non-réponse :  

1) **Données manquantes de manière complètement aléatoire** (MMCA) (on peut aussi trouver l'acronyme anglais MCAR dans les livres, pour "Missing Completely at Random"). Dans ce cas, il n'y a pas de relation entre la probabilité de manquer et les autres variables de vos données (ou de variables non mesurées). **La probabilité d'être manquante est la même pour tous les cas**. C'est une situation rare. Néanmoins, si vous avez de bonnes raisons de penser que vos données sont MMCA, l'analyse des données non manquantes (sans imputation) ne faussera pas les résultats (malgré une possible perte de puissance).  


2) **Données manquantes aléatoirement** (MA ou MAR en Anglais, pour "Missing at Random". Ce nom est en fait un peu trompeur car MA signifie que vos données sont manquantes de manière systématique et prévisible en fonction des autres variables mesurées. Par exemple, dans notre cas, les docteurs ont pu considérer que les patients présentant des frissons et des courbatures ont nécessairement de la fièvre et n'ont pas pris leur température. Cela aboutit à des observations manquantes dans la colonne fièvre, aisément prévisibles grâce aux colonnes frissons et courbatures. Si c'est vrai, nous pourrions facilement prédire que chaque observation manquante avec des frissons et des courbatures a également de la fièvre et utiliser cette information pour imputer nos données manquantes. Dans la pratique, c'est souvent plus compliqué: si un patient présente à la fois des frissons et des courbatures, il est probable qu'il ait également de la fièvre, mais pas toujours. Les données MA sont prévisibles, mais la prédiction n'est jamais parfaite. Il s'agit d'un type très courant de données manquantes 


3) **Données manquantes par omission prévisible** (MOP) aussi appelées **Données manquantes non aléatoirement** (MNAR ou NMAR en Anglais, pour "Missing not at Random" ou "Not Missing at Random"). Dans ce cas, la probabilité qu'une valeur soit manquante n'est *PAS* systématique ou prévisible à l'aide des autres informations dont nous disposons, mais elle n'est pas non plus manquante au hasard. Les données manquent pour des raisons inconnues, sur lesquelles vous n'avez aucune information. La valeur de la variable manquante est liée à la raison pour laquelle elle est manquante. Par exemple, dans nos données, l'age du patient peut manquer parce que certains patients très âgés ne savent pas ou refusent de dire quel âge ils ont. Dans cette situation, les données manquantes sur l'âge sont liées à la valeur elle-même, ne sont donc pas aléatoires ni prévisibles sur la base des autres informations dont nous disposons. Ce mécanisme de non-réponse est non ignorable, complexe et souvent, la meilleure façon d'y faire face est d'essayer de collecter plus de données ou d'informations sur la raison pour laquelle les données sont manquantes plutôt que de tenter de les imputer. 

 
En général, imputer des données MA est relativement simple, mais imputer des données MOP est complexe, difficile et souvent impossible. La plupart des méthodes d'imputation les plus répandues font l'hypothèse que les données sont de type MA.  


### Packages utiles {.unnumbered}

Voici un certain nombre de packages utiles pour l'imputation des données : **Mmisc**, **missForest** (qui utilise les forêts aléatoires pour imputer les données manquantes) et **mice** (Multivariate Imputation by Chained Equations). Dans cette section, nous nous focaliserons sur le paquet **mice**, qui met en œuvre diverses techniques. Le responsable du paquet **mice** a publié un [livre détaillé accessible en ligne](https://stefvanbuuren.name/fimd/) sur l'imputation des données manquantes.  

Voici le code pour charger le paquetage **mice** :  

```{r}
pacman::p_load(mice)
```

### Imputation par la moyenne {.unnumbered}

Parfois, dans le cas d'analyses simples ou s'il y a de bonnes raisons de penser que que les données sont de type MA, il est possible de simplement remplacer les valeurs manquantes d'une variable par la moyenne de cette variable. Par exemple, nous pourrions avoir de bonnes raisons de penser que les mesures de température manquantes dans nos données étaient MA ou normales. Voici le code permettant de créer une nouvelle variable qui remplace les valeurs de température manquantes par la valeur de température moyenne de notre ensemble de données. 

Il faut rester prudent, car dans de nombreuses situations, le remplacement des données manquantes par la moyenne peut entraîner un biais.


```{r}
linelist <- linelist %>%
  mutate(temp_replace_na_with_mean = replace_na(temp, mean(temp, na.rm = T)))
```

On peut procéder de la même manière pour remplacer des données catégoriques par une valeur spécifique. Dans nos données, imaginez que vous sachiez que toutes les observations pour lesquelles il manque une valeur de décharge (qui peut être "Décès" ou "Guéri") sont en fait des personnes décédées (remarque : ce n'est pas réellement vrai pour cet ensemble de données).


```{r}
linelist <- linelist %>%
  mutate(outcome_replace_na_with_death = replace_na(outcome, "Death"))
```

### Regression imputation {.unnumbered}

A somewhat more advanced method is to use some sort of statistical model to predict what a missing value is likely to be and replace it with the predicted value. Here is an example of creating predicted values for all the observations where temperature is missing, but age and fever are not, using simple linear regression using fever status and age in years as predictors. In practice you'd want to use a better model than this sort of simple approach.

```{r, warning=F, message=F}
simple_temperature_model_fit <- lm(temp ~ fever + age_years, data = linelist)

#using our simple temperature model to predict values just for the observations where temp is missing
predictions_for_missing_temps <- predict(simple_temperature_model_fit,
                                        newdata = linelist %>% filter(is.na(temp))) 
```

Or, using the same modeling approach through the mice package to create imputed values for the missing temperature observations:

```{r}
model_dataset <- linelist %>%
  select(temp, fever, age_years)  

temp_imputed <- mice(model_dataset,
                            method = "norm.predict",
                            seed = 1,
                            m = 1,
                            print = F)

temp_imputed_values <- temp_imputed$imp$temp

```


This is the same type of approach by some more advanced methods like using the missForest package to replace missing data with predicted values. In that case, the prediction model is a random forest instead of a linear regression. You can use other types of models to do this as well. However, while this approach works well under MCAR you should be a bit careful if you believe MAR or MNAR more accurately describes your situation. The quality of your imputation will depend on how good your prediction model is and even with a very good model the variability of your imputed data may be underestimated. 

### LOCF and BOCF {.unnumbered}

Last observation carried forward (LOCF) and baseline observation carried forward (BOCF) are imputation methods for time series/longitudinal data. The idea is to take the previous observed value as a replacement for the missing data. When multiple values are missing in succession, the method searches for the last observed value.

The `fill()` function from the **tidyr** package can be used for both LOCF and BOCF imputation (however, other packages such as **HMISC**, **zoo**, and **data.table** also include methods for doing this). To show the `fill()` syntax we'll make up a simple time series dataset containing the number of cases of a disease for each quarter of the years 2000 and 2001. However, the year value for subsequent quarters after Q1 are missing so we'll need to impute them. The `fill()` junction is also demonstrated in the [Pivoting data] page.  

```{r}
#creating our simple dataset
disease <- tibble::tribble(
  ~quarter, ~year, ~cases,
  "Q1",    2000,    66013,
  "Q2",      NA,    69182,
  "Q3",      NA,    53175,
  "Q4",      NA,    21001,
  "Q1",    2001,    46036,
  "Q2",      NA,    58842,
  "Q3",      NA,    44568,
  "Q4",      NA,    50197)

#imputing the missing year values:
disease %>% fill(year)

```

Note: make sure your data are sorted correctly before using the `fill()` function. `fill()`  defaults to filling "down" but you can also impute values in different directions by changing the `.direction` parameter. We can make a similar dataset where the year value is recorded only at the end of the year and missing for earlier quarters: 

```{r}
#creating our slightly different dataset
disease <- tibble::tribble(
  ~quarter, ~year, ~cases,
  "Q1",      NA,    66013,
  "Q2",      NA,    69182,
  "Q3",      NA,    53175,
  "Q4",    2000,    21001,
  "Q1",      NA,    46036,
  "Q2",      NA,    58842,
  "Q3",      NA,    44568,
  "Q4",    2001,    50197)

#imputing the missing year values in the "up" direction:
disease %>% fill(year, .direction = "up")

```
In this example, LOCF and BOCF are clearly the right things to do, but in more complicated situations it may be harder to decide if these methods are appropriate. For example, you may have missing laboratory values for a hospital patient after the first day. Sometimes, this can mean the lab values didn't change...but it could also mean the patient recovered and their values would be very different after the first day! Use these methods with caution.


### Multiple Imputation {.unnumbered}

The online book we mentioned earlier by the author of the **mice** package (https://stefvanbuuren.name/fimd/) contains a detailed explanation of multiple imputation and why you'd want to use it. But, here is a basic explanation of the method:

When you do multiple imputation, you create multiple datasets with the missing values imputed to plausible data values (depending on your research data you might want to create more or less of these imputed datasets, but the mice package sets the default number to 5). The difference is that rather than a single, specific value each imputed value is drawn from an estimated distribution (so it includes some randomness). As a result, each of these datasets will have slightly different different imputed values (however, the non-missing data will be the same in each of these imputed datasets). You still use some sort of predictive model to do the imputation in each of these new datasets (mice has many options for prediction methods including *Predictive Mean Matching*, *logistic regression*, and *random forest*) but the mice package can take care of many of the modeling details. 

Then, once you have created these new imputed datasets, you can apply then apply whatever statistical model or analysis you were planning to do for each of these new imputed datasets and pool the results of these models together. This works very well to reduce bias in both MCAR and many MAR settings and often results in more accurate standard error estimates.

Here is an example of applying the Multiple Imputation process to predict temperature in our linelist dataset using a age and fever status (our simplified model_dataset from above):  

```{r}
# imputing missing values for all variables in our model_dataset, and creating 10 new imputed datasets
multiple_imputation = mice(
  model_dataset,
  seed = 1,
  m = 10,
  print = FALSE) 

model_fit <- with(multiple_imputation, lm(temp ~ age_years + fever))

base::summary(mice::pool(model_fit))
```

Here we used the mice default method of imputation, which is Predictive Mean Matching. We then used these imputed datasets to separately estimate and then pool results from simple linear regressions on each of these datasets. There are many details we've glossed over and many settings you can adjust during the Multiple Imputation process while using the mice package. For example, you won't always have numerical data and might need to use other imputation methods (you can still use the mice package for many other types of data and methods). But, for a more robust analysis when missing data is a significant concern, Multiple Imputation is good solution that isn't always much more work than doing a complete case analysis. 





<!-- ======================================================= -->
## Resources { }

Vignette on the [naniar package](https://cran.r-project.org/web/packages/naniar/vignettes/getting-started-w-naniar.html)

Gallery of [missing value visualizations](https://cran.r-project.org/web/packages/naniar/vignettes/naniar-visualisation.html)

[Online book](https://stefvanbuuren.name/fimd/) about multiple imputation in R by the maintainer of the **mice** package 
